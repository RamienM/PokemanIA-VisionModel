{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f638c0-0203-40bf-8c74-e05d765b0def",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13f062b7-c411-4b62-965f-ad5a4d6c7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aab460-02eb-4cb9-9512-cca5190dc8bd",
   "metadata": {},
   "source": [
    "# Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67a4263-4c69-417b-b46f-a50f459e67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STELLE_Seg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STELLE_Seg,self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2), #H/2\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2),  # H/4\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2),  # H/8\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),  # H/4\n",
    "\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),  # H/2\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),  # H\n",
    "        )\n",
    "\n",
    "        self.segmentator = nn.Conv2d(16, 14, kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.segmentator(x)\n",
    "        return x # [B, num_classes, H, W]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3edf35-a845-4822-b721-9d3a8b75bb3f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590a7a7c-cb60-4860-bcca-a087bea82f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STELLE_Data(Dataset):\n",
    "    def __init__(self, yaml_path, split='train',img_size=(144, 160)):\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "\n",
    "        assert split in ['train', 'val', 'test'], \"Split debe ser 'train', 'val' o 'test'\"\n",
    "\n",
    "        self.image_dir = data[split]\n",
    "        self.label_dir = self.image_dir.replace('/images', '/labels')\n",
    "        self.img_size = img_size\n",
    "        self.num_classes = data['nc']\n",
    "        self.class_names = data['names']\n",
    "\n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, img_file)\n",
    "        label_path = os.path.join(self.label_dir, os.path.splitext(img_file)[0] + \".txt\")\n",
    "\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        image = image.resize((self.img_size[1], self.img_size[0]))\n",
    "        image_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "        h, w = self.img_size\n",
    "        mask = np.zeros(self.img_size, dtype=np.uint8)\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    # Se espera: al menos 1 token para clase + 6 tokens para 3 puntos (mínimo)\n",
    "                    if len(parts) < 7:\n",
    "                        continue\n",
    "    \n",
    "                    # El primer token es el ID de clase\n",
    "                    class_id = int(parts[0])\n",
    "                    # Extraer las coordenadas normalizadas (x, y)\n",
    "                    coords = list(map(float, parts[1:]))\n",
    "                    if len(coords) % 2 != 0:\n",
    "                        # Si no son pares, la línea no es válida\n",
    "                        continue\n",
    "    \n",
    "                    # Convertir la lista de coordenadas a un array y dar forma (n_puntos, 2)\n",
    "                    pts = np.array(coords, dtype=np.float32).reshape(-1, 2)\n",
    "                    # Convertir coordenadas normalizadas a píxeles\n",
    "                    pts[:, 0] *= w  # x: ancho\n",
    "                    pts[:, 1] *= h  # y: alto\n",
    "                    pts = pts.astype(np.int32)\n",
    "                    # Asegurarse que los puntos queden dentro de la imagen\n",
    "                    pts[:, 0] = np.clip(pts[:, 0], 0, w - 1)\n",
    "                    pts[:, 1] = np.clip(pts[:, 1], 0, h - 1)\n",
    "    \n",
    "                    # Dibujar el polígono en la máscara usando el valor del ID de clase\n",
    "                    cv2.fillPoly(mask, [pts], color=class_id+1)\n",
    "    \n",
    "        mask_tensor = torch.from_numpy(mask).long()\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23f19533-69a5-4b58-9a3a-5dd45a2f2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =STELLE_Data(\"dataset/data.yaml\",split='test')\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc72aaf1-8b81-4ed5-8ecc-c907978bb8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STELLE_Seg(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (middle): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (6): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  )\n",
       "  (segmentator): Conv2d(16, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = STELLE_Seg()\n",
    "model.to(device)\n",
    "checkpoint = torch.load(\"weights/STELLE_Seg.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d020fde-cab2-4c25-910d-56b43fd3065b",
   "metadata": {},
   "source": [
    "# Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "700de9f8-b23f-4571-87d1-206858bf3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy_multiclass(pred, target):\n",
    "    # pred: [B, C, H, W] logits o probs\n",
    "    # target: [B, H, W] con labels 0..C-1 (clase correcta por pixel)\n",
    "    pred_labels = pred.argmax(dim=1)\n",
    "    correct = (pred_labels == target).float()\n",
    "    return correct.sum() / correct.numel()\n",
    "\n",
    "def iou_multiclass(pred, target, num_classes=14):\n",
    "    # pred: [B, C, H, W]\n",
    "    # target: [B, H, W]\n",
    "    pred_labels = pred.argmax(dim=1)\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (pred_labels == cls)\n",
    "        target_mask = (target == cls)\n",
    "        intersection = (pred_mask & target_mask).float().sum()\n",
    "        union = (pred_mask | target_mask).float().sum()\n",
    "        if union == 0:\n",
    "            ious.append(torch.tensor(1.0))  # clase no presente -> IoU perfecta\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    return ious # Return list for per-class breaking down later\n",
    "\n",
    "def precision_multiclass(pred, target, num_classes=14):\n",
    "    pred_labels = pred.argmax(dim=1)\n",
    "    precisions = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (pred_labels == cls)\n",
    "        target_mask = (target == cls)\n",
    "        tp = (pred_mask & target_mask).sum().float()\n",
    "        fp = (pred_mask & (~target_mask)).sum().float()\n",
    "        precisions.append(tp / (tp + fp + 1e-8))\n",
    "    return precisions # Return list\n",
    "\n",
    "def recall_multiclass(pred, target, num_classes=14):\n",
    "    pred_labels = pred.argmax(dim=1)\n",
    "    recalls = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (pred_labels == cls)\n",
    "        target_mask = (target == cls)\n",
    "        tp = (pred_mask & target_mask).sum().float()\n",
    "        fn = ((~pred_mask) & target_mask).sum().float()\n",
    "        recalls.append(tp / (tp + fn + 1e-8))\n",
    "    return recalls # Return list\n",
    "\n",
    "def f1_score_multiclass(precisions, recalls): # Modified to take lists of prec/rec\n",
    "    f1s = []\n",
    "    for p, r in zip(precisions, recalls):\n",
    "        f1s.append(2 * (p * r) / (p + r + 1e-8))\n",
    "    return f1s # Return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5f95400-fee3-4359-9cdb-7fc9311f5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_multiclass_per_class(model, dataset, device, num_classes=14):\n",
    "    model.eval()\n",
    "\n",
    "    overall_pixel_accuracies = []\n",
    "\n",
    "    per_class_ious = [[] for _ in range(num_classes)]\n",
    "    per_class_precisions = [[] for _ in range(num_classes)]\n",
    "    per_class_recalls = [[] for _ in range(num_classes)]\n",
    "    per_class_f1s = [[] for _ in range(num_classes)]\n",
    "\n",
    "    # New: To store total pixel count for each class across the dataset\n",
    "    total_class_pixels = torch.zeros(num_classes, dtype=torch.long)\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        img, map_gt, *_ = dataset[i]\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "\n",
    "        if map_gt.ndim == 3 and map_gt.shape[0] == num_classes:\n",
    "            target = map_gt.argmax(dim=0).to(device)\n",
    "        else:\n",
    "            target = map_gt.to(device)\n",
    "\n",
    "        target_cpu = target.cpu() # Move target to CPU once for all calculations\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "\n",
    "        output = output.cpu()\n",
    "\n",
    "        # Accumulate pixel counts for each class from the ground truth\n",
    "        # Note: map_gt_flat should be 1D with class labels\n",
    "        unique_labels, counts = torch.unique(target_cpu, return_counts=True)\n",
    "        for label, count in zip(unique_labels, counts):\n",
    "            if 0 <= label < num_classes: # Ensure label is within expected range\n",
    "                total_class_pixels[label] += count.item()\n",
    "\n",
    "\n",
    "        pixel_acc = pixel_accuracy_multiclass(output, target_cpu)\n",
    "        overall_pixel_accuracies.append(pixel_acc.item())\n",
    "\n",
    "        ious_img = iou_multiclass(output, target_cpu, num_classes)\n",
    "        prec_img = precision_multiclass(output, target_cpu, num_classes)\n",
    "        rec_img = recall_multiclass(output, target_cpu, num_classes)\n",
    "        f1_img = f1_score_multiclass(prec_img, rec_img)\n",
    "\n",
    "        for cls_idx in range(num_classes):\n",
    "            per_class_ious[cls_idx].append(ious_img[cls_idx].item())\n",
    "            per_class_precisions[cls_idx].append(prec_img[cls_idx].item())\n",
    "            per_class_recalls[cls_idx].append(rec_img[cls_idx].item())\n",
    "            per_class_f1s[cls_idx].append(f1_img[cls_idx].item())\n",
    "\n",
    "    mean_pixel_acc = np.mean(overall_pixel_accuracies)\n",
    "\n",
    "    mean_per_class_ious = [np.mean(cls_scores) if cls_scores else 0.0 for cls_scores in per_class_ious] # Handle empty lists for IoU\n",
    "    mean_per_class_precisions = [np.mean(cls_scores) if cls_scores else 0.0 for cls_scores in per_class_precisions]\n",
    "    mean_per_class_recalls = [np.mean(cls_scores) if cls_scores else 0.0 for cls_scores in per_class_recalls]\n",
    "    mean_per_class_f1s = [np.mean(cls_scores) if cls_scores else 0.0 for cls_scores in per_class_f1s]\n",
    "\n",
    "    # Calculate overall mean (macro-average) across all classes (unweighted)\n",
    "    overall_mean_iou_unweighted = np.mean(mean_per_class_ious)\n",
    "    overall_mean_precision_unweighted = np.mean(mean_per_class_precisions)\n",
    "    overall_mean_recall_unweighted = np.mean(mean_per_class_recalls)\n",
    "    overall_mean_f1_unweighted = np.mean(mean_per_class_f1s)\n",
    "\n",
    "    # Calculate WEIGHTED Macro-averages for Precision, Recall, F1\n",
    "    # Use total_class_pixels as weights. Normalize weights.\n",
    "    total_pixels_sum = total_class_pixels.sum().item()\n",
    "    if total_pixels_sum == 0:\n",
    "        # Avoid division by zero if dataset is empty or all classes are truly empty\n",
    "        weighted_precision = 0.0\n",
    "        weighted_recall = 0.0\n",
    "        weighted_f1 = 0.0\n",
    "    else:\n",
    "        # Filter out classes that never appeared (total_class_pixels[cls_idx] == 0)\n",
    "        # to avoid multiplying by zero weight for non-existent classes.\n",
    "        # Ensure that scores from non-existent classes (which might be 0.0 if cls_scores is empty)\n",
    "        # don't get multiplied by a zero weight if they actually contributed a zero score due to 0 TP/FP/FN.\n",
    "        # It's better to exclude classes that truly have 0 ground truth pixels.\n",
    "\n",
    "        weighted_precisions_list = []\n",
    "        weighted_recalls_list = []\n",
    "        weighted_f1s_list = []\n",
    "        valid_weights = []\n",
    "\n",
    "        for cls_idx in range(num_classes):\n",
    "            if total_class_pixels[cls_idx] > 0: # Only include classes that actually have pixels in the ground truth\n",
    "                weighted_precisions_list.append(mean_per_class_precisions[cls_idx] * total_class_pixels[cls_idx].item())\n",
    "                weighted_recalls_list.append(mean_per_class_recalls[cls_idx] * total_class_pixels[cls_idx].item())\n",
    "                weighted_f1s_list.append(mean_per_class_f1s[cls_idx] * total_class_pixels[cls_idx].item())\n",
    "                valid_weights.append(total_class_pixels[cls_idx].item())\n",
    "\n",
    "        if sum(valid_weights) > 0:\n",
    "            weighted_precision = sum(weighted_precisions_list) / sum(valid_weights)\n",
    "            weighted_recall = sum(weighted_recalls_list) / sum(valid_weights)\n",
    "            weighted_f1 = sum(weighted_f1s_list) / sum(valid_weights)\n",
    "        else:\n",
    "            weighted_precision = 0.0\n",
    "            weighted_recall = 0.0\n",
    "            weighted_f1 = 0.0\n",
    "\n",
    "\n",
    "    return {\n",
    "        'overall_pixel_acc': mean_pixel_acc,\n",
    "        'overall_iou_unweighted': overall_mean_iou_unweighted, # Renamed for clarity\n",
    "        'overall_precision_unweighted': overall_mean_precision_unweighted,\n",
    "        'overall_recall_unweighted': overall_mean_recall_unweighted,\n",
    "        'overall_f1_unweighted': overall_mean_f1_unweighted,\n",
    "        'overall_precision_weighted': weighted_precision, # New: Weighted Macro Precision\n",
    "        'overall_recall_weighted': weighted_recall,       # New: Weighted Macro Recall\n",
    "        'overall_f1_weighted': weighted_f1,               # New: Weighted Macro F1\n",
    "        'per_class_iou': mean_per_class_ious,\n",
    "        'per_class_precision': mean_per_class_precisions,\n",
    "        'per_class_recall': mean_per_class_recalls,\n",
    "        'per_class_f1': mean_per_class_f1s,\n",
    "        'total_class_pixels_in_testset': total_class_pixels.tolist() # New: Return pixel counts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e3eb710-68fe-4eaf-9d20-2301d63a54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(model, dataset, device, warmup=5):\n",
    "    model.eval()\n",
    "    times = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        img, *_ = dataset[i]\n",
    "        img = img.unsqueeze(0).to(device)  # (1, 1, H, W)\n",
    "\n",
    "        if i < warmup:\n",
    "            with torch.no_grad():\n",
    "                model(img)\n",
    "            continue\n",
    "\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            model(img)\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_time = np.mean(times)\n",
    "    return avg_time, 1.0 / avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc697e18-7fea-4320-a5e5-65f33b7be25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:02<00:00, 53.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Pixel Accuracy: 0.9564\n",
      "Overall Mean IoU (Unweighted): 0.8970\n",
      "Overall Mean Precision (Unweighted): 0.3409\n",
      "Overall Mean Recall (Unweighted): 0.3366\n",
      "Overall Mean F1 Score (Unweighted): 0.3347\n",
      "\n",
      "Overall Precision (Weighted by Pixels): 0.7393\n",
      "Overall Recall (Weighted by Pixels): 0.7445\n",
      "Overall F1 Score (Weighted by Pixels): 0.7401\n",
      "\n",
      "--- Per-Class Metrics ---\n",
      "Class 0:\n",
      "  IoU: 0.8807\n",
      "  Precision: 0.8689\n",
      "  Recall: 0.8653\n",
      "  F1 Score: 0.8663\n",
      "Class 1:\n",
      "  IoU: 0.9366\n",
      "  Precision: 0.3457\n",
      "  Recall: 0.3480\n",
      "  F1 Score: 0.3467\n",
      "Class 2:\n",
      "  IoU: 0.8280\n",
      "  Precision: 0.3001\n",
      "  Recall: 0.2753\n",
      "  F1 Score: 0.2785\n",
      "Class 3:\n",
      "  IoU: 0.8025\n",
      "  Precision: 0.8478\n",
      "  Recall: 0.8883\n",
      "  F1 Score: 0.8571\n",
      "Class 4:\n",
      "  IoU: 0.9820\n",
      "  Precision: 0.0452\n",
      "  Recall: 0.0428\n",
      "  F1 Score: 0.0439\n",
      "Class 5:\n",
      "  IoU: 0.8760\n",
      "  Precision: 0.2701\n",
      "  Recall: 0.2158\n",
      "  F1 Score: 0.2332\n",
      "Class 6:\n",
      "  IoU: 0.8994\n",
      "  Precision: 0.8593\n",
      "  Recall: 0.8787\n",
      "  F1 Score: 0.8658\n",
      "Class 7:\n",
      "  IoU: 0.7496\n",
      "  Precision: 0.4087\n",
      "  Recall: 0.4231\n",
      "  F1 Score: 0.4118\n",
      "Class 8:\n",
      "  IoU: 0.9278\n",
      "  Precision: 0.0652\n",
      "  Recall: 0.0434\n",
      "  F1 Score: 0.0484\n",
      "Class 9:\n",
      "  IoU: 0.8868\n",
      "  Precision: 0.4018\n",
      "  Recall: 0.4007\n",
      "  F1 Score: 0.3980\n",
      "Class 10:\n",
      "  IoU: 0.9506\n",
      "  Precision: 0.0130\n",
      "  Recall: 0.0129\n",
      "  F1 Score: 0.0129\n",
      "Class 11:\n",
      "  IoU: 0.9127\n",
      "  Precision: 0.2494\n",
      "  Recall: 0.2383\n",
      "  F1 Score: 0.2423\n",
      "Class 12:\n",
      "  IoU: 0.9590\n",
      "  Precision: 0.0311\n",
      "  Recall: 0.0127\n",
      "  F1 Score: 0.0149\n",
      "Class 13:\n",
      "  IoU: 0.9663\n",
      "  Precision: 0.0658\n",
      "  Recall: 0.0672\n",
      "  F1 Score: 0.0664\n",
      "\n",
      "--- Total Pixels per Class in Testset ---\n",
      "Class 0: 1334094 pixels\n",
      "Class 1: 262898 pixels\n",
      "Class 2: 21322 pixels\n",
      "Class 3: 36245 pixels\n",
      "Class 4: 135384 pixels\n",
      "Class 5: 25355 pixels\n",
      "Class 6: 1066867 pixels\n",
      "Class 7: 24150 pixels\n",
      "Class 8: 2247 pixels\n",
      "Class 9: 24732 pixels\n",
      "Class 10: 487 pixels\n",
      "Class 11: 24583 pixels\n",
      "Class 12: 2619 pixels\n",
      "Class 13: 80297 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model_multiclass_per_class(model, dataset, device, num_classes=14)\n",
    "\n",
    "print(f\"Overall Pixel Accuracy: {results['overall_pixel_acc']:.4f}\")\n",
    "print(f\"Overall Mean IoU (Unweighted): {results['overall_iou_unweighted']:.4f}\") # Renamed\n",
    "print(f\"Overall Mean Precision (Unweighted): {results['overall_precision_unweighted']:.4f}\") # Renamed\n",
    "print(f\"Overall Mean Recall (Unweighted): {results['overall_recall_unweighted']:.4f}\") # Renamed\n",
    "print(f\"Overall Mean F1 Score (Unweighted): {results['overall_f1_unweighted']:.4f}\") # Renamed\n",
    "\n",
    "print(f\"\\nOverall Precision (Weighted by Pixels): {results['overall_precision_weighted']:.4f}\") # NEW\n",
    "print(f\"Overall Recall (Weighted by Pixels): {results['overall_recall_weighted']:.4f}\")       # NEW\n",
    "print(f\"Overall F1 Score (Weighted by Pixels): {results['overall_f1_weighted']:.4f}\")         # NEW\n",
    "\n",
    "print(\"\\n--- Per-Class Metrics ---\")\n",
    "for cls_idx in range(14):\n",
    "    print(f\"Class {cls_idx}:\")\n",
    "    print(f\"  IoU: {results['per_class_iou'][cls_idx]:.4f}\")\n",
    "    print(f\"  Precision: {results['per_class_precision'][cls_idx]:.4f}\")\n",
    "    print(f\"  Recall: {results['per_class_recall'][cls_idx]:.4f}\")\n",
    "    print(f\"  F1 Score: {results['per_class_f1'][cls_idx]:.4f}\")\n",
    "\n",
    "print(\"\\n--- Total Pixels per Class in Testset ---\") # NEW\n",
    "for cls_idx, count in enumerate(results['total_class_pixels_in_testset']):\n",
    "    print(f\"Class {cls_idx}: {count} pixels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2121c23-af13-4cce-929d-636ffb4f610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tiempo de inferencia ===\n",
      "Tiempo medio por imagen: 0.0010 segundos\n",
      "Imágenes por segundo (FPS): 969.01\n"
     ]
    }
   ],
   "source": [
    "avg_time, fps = measure_inference_time(model, dataset, device=device)\n",
    "\n",
    "print(\"\\n=== Tiempo de inferencia ===\")\n",
    "print(f\"Tiempo medio por imagen: {avg_time:.4f} segundos\")\n",
    "print(f\"Imágenes por segundo (FPS): {fps:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
